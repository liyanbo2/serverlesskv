{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e265e741c742dc857e7c5d2db25144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 172.00 MiB. GPU 2 has a total capacity of 31.74 GiB of which 21.12 MiB is free. Process 1490337 has 30.93 GiB memory in use. Process 1591256 has 808.00 MiB memory in use. Of the allocated memory 500.02 MiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:2\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m LlamaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m use_cache \u001b[38;5;129;01min\u001b[39;00m ( \u001b[38;5;28;01mFalse\u001b[39;00m,\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     11\u001b[0m   times \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:3838\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3829\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3831\u001b[0m     (\n\u001b[1;32m   3832\u001b[0m         model,\n\u001b[1;32m   3833\u001b[0m         missing_keys,\n\u001b[1;32m   3834\u001b[0m         unexpected_keys,\n\u001b[1;32m   3835\u001b[0m         mismatched_keys,\n\u001b[1;32m   3836\u001b[0m         offload_index,\n\u001b[1;32m   3837\u001b[0m         error_msgs,\n\u001b[0;32m-> 3838\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3845\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3846\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3849\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3850\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3855\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3857\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3858\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4298\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4294\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4295\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4296\u001b[0m                 )\n\u001b[1;32m   4297\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4298\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4299\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4300\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4301\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4302\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4303\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4304\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4305\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4306\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4307\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4312\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4313\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4314\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4315\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:895\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[1;32m    884\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_quantized\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mrequires_parameters_quantization)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    893\u001b[0m ):\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 895\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    897\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:416\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    414\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 416\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 2 has a total capacity of 31.74 GiB of which 21.12 MiB is free. Process 1490337 has 30.93 GiB memory in use. Process 1591256 has 808.00 MiB memory in use. Of the allocated memory 500.02 MiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "model_path = \"/dataset/crosspipe/OriginModel/Llama-2-7b-chat-hf/\"\n",
    " \n",
    "device = \"cuda:2\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)\n",
    "model = LlamaForCausalLM.from_pretrained(model_path, device_map=device)\n",
    "for use_cache in ( False,True):\n",
    "  times = []\n",
    "  for _ in range(1):  # measuring 10 generations\n",
    "      start = time.time()\n",
    "      input = tokenizer(\"What is KV caching?\", return_tensors=\"pt\").to(device)\n",
    "      outputs = model.generate(**input, use_cache=use_cache, max_new_tokens=1000, temperature=0.00001)\n",
    "      times.append(time.time() - start)\n",
    "      print(outputs)\n",
    "  print(f\"{'With' if use_cache else 'Without'} KV caching: {round(np.mean(times), 3)} +- {round(np.std(times), 3)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor([[    1,  1724,   338,   476, 29963, 22488, 29973,    13,    13, 29968,\n",
    "         29963, 22488,   338,   263, 11043,  1304,   297,  7047,  5849,   304,\n",
    "         11157,   278,  4180,   310,  8324,   491, 15446, 13672, 20592,   848,\n",
    "           297,   263,  7090, 29889,   476, 29963, 15028,   363,   376,  1989,\n",
    "         29899,  1767,  1699,   607, 14637,   304,   278,  1134,   310,   848,\n",
    "          6087,   297,   278,  7090, 29889,    13,    13,   797,   263,   476,\n",
    "         29963,  7090, 29892,   848,   338,  6087,   408,   263,  5101,   310,\n",
    "           263,  1820,   322,   263,   995, 29889,   450,  1820,   338,  1304,\n",
    "           304, 12439,   278,   848, 29892,   322,   278,   995,   338,   278,\n",
    "           848,  3528, 29889,   450,  7090,   338, 12234,  8762,   408,   263,\n",
    "           848,  3829, 29892,  1316,   408,   263,  6608,  1591,   470,   263,\n",
    "          5447, 29892,   393,  6511,   363,  8543,  1106, 14340,   322, 11217,\n",
    "           310,   278,  6087,   848, 29889,    13,    13, 29968, 29963, 22488,\n",
    "           338, 15574,  1304,   297,  1856,  8324,   304, 11157,   278,  4180,\n",
    "           310,  2566,  9365, 29889,  8669,   310,  2346,   292,   278,  2566,\n",
    "           363,  1432,  2009, 29892,   278,  2280,   508,   671,   278,   476,\n",
    "         29963,  7090,   304,  3787, 13672, 20592,   848, 29892,  1316,   408,\n",
    "          1404,  4867,  2472,   470, 13672, 20592,  6515, 29889,   910, 26830,\n",
    "           278,  1353,   310,  2566,  9365, 29892,   607,   508, 11157,   278,\n",
    "          2280, 29915, 29879,  4180,   322,  8716,  3097, 29889,    13,    13,\n",
    "         29968, 29963, 22488,   508,   884,   367,  1304,   297,   916, 10161,\n",
    "           310,  7047,  5849, 29892,  1316,   408, 29901,    13,    13, 29930,\n",
    "           315,  9733, 13672, 20592,   848,   297,   263,  1856,  2280,   304,\n",
    "         10032,   278,  1353,   310,  2566,  9365, 29889,    13, 29930,   624,\n",
    "          8253, 15562, 29892,  1316,   408,  1404,  5821,  2063,   470,  2740,\n",
    "          4955, 29892,   297,   263,  7090,   304, 11157,   278,  4180,   310,\n",
    "           263,  1856,  2280, 29889,    13, 29930,   315,  9733, 13672, 20592,\n",
    "           848,   297,   263, 13235,  1788,   304, 10032,   278,  2254,   373,\n",
    "           278,  1788,   322, 11157,   967,  8716,  3097, 29889,    13,    13,\n",
    "           797, 15837, 29892,   476, 29963, 22488,   338,   263, 11043,  1304,\n",
    "           304, 11157,   278,  4180,   310,  8324,   491, 15446, 13672, 20592,\n",
    "           848,   297,   263,  7090, 29889,   739,   338, 15574,  1304,   297,\n",
    "          1856,  8324,   304, 10032,   278,  1353,   310,  2566,  9365, 29892,\n",
    "           541,   508,   884,   367,  1304,   297,   916, 10161,   310,  7047,\n",
    "          5849,   304, 11157,  4180,   322,  8716,  3097, 29889,     2]],\n",
    "       device='cuda:2')\n",
    "With KV caching: 18.327 +- 0.0 seconds\n",
    "tensor([[    1,  1724,   338,   476, 29963, 22488, 29973,    13,    13, 29968,\n",
    "         29963, 22488,   338,   263, 11043,  1304,   297,  7047,  5849,   304,\n",
    "         11157,   278,  4180,   310,  8324,   491, 15446, 13672, 20592,   848,\n",
    "           297,   263,  7090, 29889,   476, 29963, 15028,   363,   376,  1989,\n",
    "         29899,  1767,  1699,   607, 14637,   304,   278,  1134,   310,   848,\n",
    "          6087,   297,   278,  7090, 29889,    13,    13,   797,   263,   476,\n",
    "         29963,  7090, 29892,   848,   338,  6087,   408,   263,  5101,   310,\n",
    "           263,  1820,   322,   263,   995, 29889,   450,  1820,   338,  1304,\n",
    "           304, 12439,   278,   848, 29892,   322,   278,   995,   338,   278,\n",
    "           848,  3528, 29889,   450,  7090,   338, 12234,  8762,   408,   263,\n",
    "           848,  3829, 29892,  1316,   408,   263,  6608,  1591,   470,   263,\n",
    "          5447, 29892,   393,  6511,   363,  8543,  1106, 14340,   322, 11217,\n",
    "           310,   278,  6087,   848, 29889,    13,    13, 29968, 29963, 22488,\n",
    "           338, 15574,  1304,   297,  1856,  8324,   304, 11157,   278,  4180,\n",
    "           310,  2566,  9365, 29889,  8669,   310,  2346,   292,   278,  2566,\n",
    "           363,  1432,  2009, 29892,   278,  2280,   508,   671,   278,   476,\n",
    "         29963,  7090,   304,  3787, 13672, 20592,   848, 29892,  1316,   408,\n",
    "          1404,  4867,  2472,   470, 13672, 20592,  6515, 29889,   910, 26830,\n",
    "           278,  1353,   310,  2566,  9365, 29892,   607,   508, 11157,   278,\n",
    "          2280, 29915, 29879,  4180,   322,  8716,  3097, 29889,    13,    13,\n",
    "         29968, 29963, 22488,   508,   884,   367,  1304,   297,   916, 10161,\n",
    "           310,  7047,  5849, 29892,  1316,   408, 29901,    13,    13, 29930,\n",
    "           315,  9733, 13672, 20592,   848,   297,   263,  1856,  2280,   304,\n",
    "         10032,   278,  1353,   310,  2566,  9365, 29889,    13, 29930,   624,\n",
    "          8253, 15562, 29892,  1316,   408,  1404,  5821,  2063,   470,  2740,\n",
    "          4955, 29892,   297,   263,  7090,   304, 11157,   278,  4180,   310,\n",
    "           263,  1856,  2280, 29889,    13, 29930,   315,  9733, 13672, 20592,\n",
    "           848,   297,   263, 13235,  1788,   304, 10032,   278,  2254,   373,\n",
    "           278,  1788,   322, 11157,   967,  8716,  3097, 29889,    13,    13,\n",
    "           797, 15837, 29892,   476, 29963, 22488,   338,   263, 11043,  1304,\n",
    "           304, 11157,   278,  4180,   310,  8324,   491, 15446, 13672, 20592,\n",
    "           848,   297,   263,  7090, 29889,   739,   338, 15574,  1304,   297,\n",
    "          1856,  8324,   304, 10032,   278,  1353,   310,  2566,  9365, 29892,\n",
    "           541,   508,   884,   367,  1304,   297,   916, 10161,   310,  7047,\n",
    "          5849,   304, 11157,  4180,   322,  8716,  3097, 29889,     2]],\n",
    "       device='cuda:2')\n",
    "Without KV caching: 80.208 +- 0.0 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor([[    1,  1724,   338,   476, 29963, 22488, 29973,    13,    13, 29968,\n",
    "         29963, 22488,   338,   263, 11043,  1304,   297,  7047,  5849,   304,\n",
    "         11157,   278,  4180,   310,  8324,   491, 15446, 13672, 20592,   848,\n",
    "           297,   263,  7090, 29889,   476, 29963, 15028,   363,   376,  1989,\n",
    "         29899,  1767,  1699,   607, 14637,   304,   278,  1134,   310,   848,\n",
    "          6087,   297,   278,  7090, 29889,    13,    13,   797,   263,   476,\n",
    "         29963,  7090, 29892,   848,   338,  6087,   408,   263,  5101,   310,\n",
    "           263,  1820,   322,   263,   995, 29889,   450,  1820,   338,  1304,\n",
    "           304, 12439,   278,   848, 29892,   322,   278,   995,   338,   278,\n",
    "           848,  3528, 29889,   450,  7090,   338, 12234,  8762,   408,   263,\n",
    "           848,  3829, 29892,  1316,   408,   263,  6608,  1591,   470,   263,\n",
    "          5447, 29892,   393,  6511,   363,  8543,  1106, 14340,   322, 11217,\n",
    "           310,   278,  6087,   848, 29889,    13,    13, 29968, 29963, 22488,\n",
    "           338, 15574,  1304,   297,  1856,  8324,   304, 11157,   278,  4180,\n",
    "           310,  2566,  9365, 29889,  8669,   310,  2346,   292,   278,  2566,\n",
    "           363,  1432,  2009, 29892,   278,  2280,   508,   671,   278,   476,\n",
    "         29963,  7090,   304,  3787, 13672, 20592,   848, 29892,  1316,   408,\n",
    "          1404,  4867,  2472,   470, 13672, 20592,  6515, 29889,   910, 26830,\n",
    "           278,  1353,   310,  2566,  9365, 29892,   607,   508, 11157,   278,\n",
    "          2280, 29915, 29879,  4180,   322,  8716,  3097, 29889,    13,    13,\n",
    "         29968, 29963, 22488,   508,   884,   367,  1304,   297,   916, 10161,\n",
    "           310,  7047,  5849, 29892,  1316,   408, 29901,    13,    13, 29930,\n",
    "           315,  9733, 13672, 20592,   848,   297,   263,  1856,  2280,   304,\n",
    "         10032,   278,  1353,   310,  2566,  9365, 29889,    13, 29930,   624,\n",
    "          8253, 15562, 29892,  1316,   408,  1404,  5821,  2063,   470,  2740,\n",
    "...\n",
    "           541,   508,   884,   367,  1304,   297,   916, 10161,   310,  7047,\n",
    "          5849,   304, 11157,  4180,   322,  8716,  3097, 29889,     2]],\n",
    "       device='cuda:2')\n",
    "With KV caching: 17.642 +- 0.0 seconds\n",
    "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8e5030c88646d3a29ba5f30cf6bbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "model_path = \"/dataset/crosspipe/OriginModel/Llama-2-7b-chat-hf/\"\n",
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = LlamaForCausalLM.from_pretrained(model_path, device_map=device)\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.llama.tokenization_llama.LlamaTokenizer"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [\n",
    "    \"please tell me What is KV caching?\",\n",
    "    \"what can i do to help you to do something?\"\n",
    "]\n",
    "inputs = tokenizer(input_texts,truncation=True,padding=True,max_length=256,return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,  3113,  2649,   592,  1724,   338,   476, 29963, 22488, 29973,\n",
       "             2,     2],\n",
       "        [    1,   825,   508,   474,   437,   304,  1371,   366,   304,   437,\n",
       "          1554, 29973]], device='cuda:3'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:3')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['please tell me What is KV caching?s\\n\\nKV caching is a mechanism for storing data in a key-value store, which is a type of data structure that stores data as a collection of key-value pairs. The key-value pairs are typically stored in a distributed database or a distributed cache, which allows for efficient retrieval and update of the data.\\nKV caching is commonly used in web applications to improve performance by reducing the number of database queries required to retrieve data. For example, a web application might use KV caching to store frequently accessed data, such as user preferences or session data, in a cache rather than retrieving it from the database every time it is needed. This can significantly reduce the load on the database and improve the overall performance of the application.\\nKV caching can be implemented using a variety of technologies, including:\\n1. Redis: A popular open-source key-value store that provides a fast, in-memory data structure for storing and retrieving data.\\n2. Memcached: A distributed memory caching system that is commonly used to speed up dynamic web applications by alleviating database load.\\n3. Apache Ignite: An in-memory data fabric that provides a distributed cache, data grid, and stream processing platform.\\n4. Hazelcast: An open-source in-memory data grid that provides a distributed cache, map, and queue.\\n5. Riak KV: A distributed key-value store that provides a highly available and fault-tolerant data storage solution.\\n6. Amazon DynamoDB: A fully managed NoSQL database service that provides fast and predictable performance with seamless scalability.\\nKV caching can be used in a variety of scenarios, including:\\n1. Session management: KV caching can be used to store user session data, such as user IDs and session keys, in a cache instead of storing it in the database.\\n2. Caching frequently accessed data: KV caching can be used to store frequently accessed data, such as product information or search results, in a cache to reduce the number of database queries required to retrieve the data.\\n3. Real-time analytics: KV caching can be used to store real-time analytics data, such as user behavior or system metrics, in a cache to reduce the load on the database and provide faster access to the data.\\n4. Offline applications: KV caching can be used to store data offline, such as in an airplane mode or a low-network environment, and then sync the data with the database when a connection is available.\\n5. Data aggregation: KV caching can be used to aggregate data from multiple sources, such as logs or sensor data, in a cache to reduce the load on the database and provide faster access to the data.\\n6. Machine learning: KV caching can be used to store machine learning models and their parameters in a cache to reduce the load on the database and provide faster access to the data.\\nIn summary, KV caching is a mechanism for storing data in a key-value store, which can improve the performance of web applications by reducing the number of database queries required to retrieve data. It can be implemented using a variety of technologies and can be used in a variety of scenarios, including session management, caching frequently accessed data, real-time analytics, offline applications, data aggregation, and machine learning.', 'what can i do to help you to do something?\\n\\nPlease provide more context or clarify your question so I can better understand how to assist you.']\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(**inputs, max_new_tokens=1000)\n",
    "decoded_output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way to decode❤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please tell me What is KV caching?s\n",
      "\n",
      "KV caching is a mechanism for storing data in a key-value store, which is a type of data structure that stores data as a collection of key-value pairs. The key-value pairs are typically stored in a distributed database or a distributed cache, which allows for efficient retrieval and update of the data.\n",
      "KV caching is commonly used in web applications to improve performance by reducing the number of database queries required to retrieve data. For example, a web application might use KV caching to store frequently accessed data, such as user preferences or session data, in a cache rather than retrieving it from the database every time it is needed. This can significantly reduce the load on the database and improve the overall performance of the application.\n",
      "KV caching can be implemented using a variety of technologies, including:\n",
      "1. Redis: A popular open-source key-value store that provides a fast, in-memory data structure for storing and retrieving data.\n",
      "2. Memcached: A distributed memory caching system that is commonly used to speed up dynamic web applications by alleviating database load.\n",
      "3. Apache Ignite: An in-memory data fabric that provides a distributed cache, data grid, and stream processing platform.\n",
      "4. Hazelcast: An open-source in-memory data grid that provides a distributed cache, map, and queue.\n",
      "5. Riak KV: A distributed key-value store that provides a highly available and fault-tolerant data storage solution.\n",
      "6. Amazon DynamoDB: A fully managed NoSQL database service that provides fast and predictable performance with seamless scalability.\n",
      "KV caching can be used in a variety of scenarios, including:\n",
      "1. Session management: KV caching can be used to store user session data, such as user IDs and session keys, in a cache instead of storing it in the database.\n",
      "2. Caching frequently accessed data: KV caching can be used to store frequently accessed data, such as product information or search results, in a cache to reduce the number of database queries required to retrieve the data.\n",
      "3. Real-time analytics: KV caching can be used to store real-time analytics data, such as user behavior or system metrics, in a cache to reduce the load on the database and provide faster access to the data.\n",
      "4. Offline applications: KV caching can be used to store data offline, such as in an airplane mode or a low-network environment, and then sync the data with the database when a connection is available.\n",
      "5. Data aggregation: KV caching can be used to aggregate data from multiple sources, such as logs or sensor data, in a cache to reduce the load on the database and provide faster access to the data.\n",
      "6. Machine learning: KV caching can be used to store machine learning models and their parameters in a cache to reduce the load on the database and provide faster access to the data.\n",
      "In summary, KV caching is a mechanism for storing data in a key-value store, which can improve the performance of web applications by reducing the number of database queries required to retrieve data. It can be implemented using a variety of technologies and can be used in a variety of scenarios, including session management, caching frequently accessed data, real-time analytics, offline applications, data aggregation, and machine learning.\n",
      "what can i do to help you to do something?\n",
      "\n",
      "Please provide more context or clarify your question so I can better understand how to assist you.\n"
     ]
    }
   ],
   "source": [
    "generated_ids = generated_ids.tolist()\n",
    "\n",
    "# 解码每一行\n",
    "decoded_texts = [tokenizer.decode(ids, skip_special_tokens=True) for ids in generated_ids]\n",
    "\n",
    "# 打印解码后的文本\n",
    "for text in decoded_texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['please tell me What is KV caching?s\\n\\nKV caching is a mechanism for storing data in a key-value store, which is a type of data structure that stores data as a collection of key-value pairs. The key-value pairs are typically stored in a distributed database or a distributed cache, which allows for efficient retrieval and update of the data.\\nKV caching is commonly used in web applications to improve performance by reducing the number of database queries required to retrieve data. For example, a web application might use KV caching to store frequently accessed data, such as user preferences or session data, in a cache rather than retrieving it from the database every time it is needed. This can significantly reduce the load on the database and improve the overall performance of the application.\\nKV caching can be implemented using a variety of technologies, including:\\n1. Redis: A popular open-source key-value store that provides a fast, in-memory data structure for storing and retrieving data.\\n2. Memcached: A distributed memory caching system that is commonly used to speed up dynamic web applications by alleviating database load.\\n3. Apache Ignite: An in-memory data fabric that provides a distributed cache, data grid, and stream processing platform.\\n4. Hazelcast: An open-source in-memory data grid that provides a distributed cache, map, and queue.\\n5. Riak KV: A distributed key-value store that provides a highly available and fault-tolerant data storage solution.\\n6. Amazon DynamoDB: A fully managed NoSQL database service that provides fast and predictable performance with seamless scalability.\\nKV caching can be used in a variety of scenarios, including:\\n1. Session management: KV caching can be used to store user session data, such as user IDs and session keys, in a cache instead of storing it in the database.\\n2. Caching frequently accessed data: KV caching can be used to store frequently accessed data, such as product information or search results, in a cache to reduce the number of database queries required to retrieve the data.\\n3. Real-time analytics: KV caching can be used to store real-time analytics data, such as user behavior or system metrics, in a cache to reduce the load on the database and provide faster access to the data.\\n4. Offline applications: KV caching can be used to store data offline, such as in an airplane mode or a low-network environment, and then sync the data with the database when a connection is available.\\n5. Data aggregation: KV caching can be used to aggregate data from multiple sources, such as logs or sensor data, in a cache to reduce the load on the database and provide faster access to the data.\\n6. Machine learning: KV caching can be used to store machine learning models and their parameters in a cache to reduce the load on the database and provide faster access to the data.\\nIn summary, KV caching is a mechanism for storing data in a key-value store, which can improve the performance of web applications by reducing the number of database queries required to retrieve data. It can be implemented using a variety of technologies and can be used in a variety of scenarios, including session management, caching frequently accessed data, real-time analytics, offline applications, data aggregation, and machine learning.',\n",
       " 'what can i do to help you to do something?\\n\\nPlease provide more context or clarify your question so I can better understand how to assist you.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "generated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
